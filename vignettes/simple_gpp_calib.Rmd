
---
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{P-model usage}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
---

```{r}
# library and data loading
library(rsofun)
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
library(cowplot)

driver <- read_rds("/data_2/FluxDataKit/v3.4/zenodo_upload/rsofun_driver_data_v3.4.rds") # currently only on workstation


plot_eval <- function(df, is_gpp = TRUE, return_gg1 = FALSE, return_gg2 = FALSE){
  
  use_col <- ifelse(is_gpp, "tomato", "royalblue")
  use_lab <- ifelse(
    is_gpp,
    expression(paste("GPP (g C m"^-2, "s"^-1, ")")), 
    expression(paste("LE (W m"^-2, ")"))
    )
  use_lab_obs <- ifelse(
    is_gpp,
    expression(paste("Observed GPP (g C m"^-2, "s"^-1, ")")), 
    expression(paste("Observed LE (W m"^-2, ")"))
    )
  use_lab_mod <- ifelse(
    is_gpp,
    expression(paste("Modeled GPP (g C m"^-2, "s"^-1, ")")), 
    expression(paste("Modeled LE (W m"^-2, ")"))
    )
  lims <- ifelse(
    is_gpp,
    c(-0.5, 10),
    c(-20, 175)
  )
   
  # Plot GPP observed and modelled quartiles by day-of-year
  gg1 <- df |> 
    tidyr::pivot_longer(c(mod, obs), names_to = "type", values_to = "var") |> 
    mutate(doy = lubridate::yday(date)) |> 
    group_by(doy, type) |> 
    summarise(
      var_q25 = quantile(var, probs = c(0.25), na.rm = TRUE),
      var_q75 = quantile(var, probs = c(0.75), na.rm = TRUE)
      ) |> 
    ggplot() +
    geom_ribbon(
      aes(
        x = doy,
        ymin = var_q25,
        ymax = var_q75,
        fill = type
        ),
      alpha = 0.75
    ) +
    scale_fill_manual(
      name = "",
      values = c(
        "mod" = use_col,
        "obs" = 'grey20'
        ),
      labels = c(
        "mod" = "Mod.",
        "obs" = "Obs."
      )) +
    theme_classic() +
    theme() +
    labs(
      x = 'Date',
      y = use_lab,
      colour = ""
    )
  
  # get fit metrics
  rsq_val <- yardstick::rsq(df, mod, obs) |> pull(.estimate)
  rmse_val <- yardstick::rmse(df, mod, obs) |> pull(.estimate)
  bias_val <- mean(df$mod - df$obs, na.rm = TRUE)
  linmod <- lm(obs ~ mod + 0, data = df)
  slope_val <- coef(linmod)
  n_val <- df |> tidyr::drop_na() |> nrow()
  
  rsq_lab <- format(rsq_val, digits = 3)
  rmse_lab <- format(rmse_val, digits = 3)
  bias_lab <- format(bias_val, digits = 3)
  slope_lab <- format(slope_val, digits = 3)
  n_lab <- n_val
  
  subtitle <- bquote(italic(R)^2 == .(rsq_lab) ~ ~
                    RMSE == .(rmse_lab) ~ ~
                    bias == .(bias_lab) ~ ~
                    slope == .(slope_lab) ~ ~
                    italic(N) == .(n_lab))
  
  # plot modelled vs. observed (actually the reverse)
  gg2 <- df |> 
    ggplot(aes(x = mod, y = obs)) +
    geom_hex(bins = 50, show.legend = FALSE) +
    theme_classic() +
    geom_abline(intercept = 0, slope = 1, linetype = "dotted") +
    geom_hline(yintercept = 0, linetype = "dotted") +
    geom_vline(xintercept = 0, linetype = "dotted")+ 
    geom_smooth(method = "lm", formula = y ~ x + 0, color = "red", size = 0.5, se = FALSE) +
    xlim(lims[1], lims[2]) + 
    ylim(lims[1], lims[2]) +
    labs(
      x = use_lab_mod,
      y = use_lab_obs,
      subtitle = subtitle
    )
  
  if (is_gpp){
    gg2 <- gg2 +
      khroma::scale_fill_batlowW(trans = "log", reverse = TRUE)
  } else {
    gg2 <- gg2 +
      khroma::scale_fill_davos(trans = "log", reverse = TRUE)

  }
  
  if (return_gg1){
    return(gg1)
  } else if (return_gg2){
    return(gg2)
  } else {
    cow <- cowplot::plot_grid(gg1, gg2, nrow = 1)
    return(cow)
  }
}
```

## Scope

In this Vignette I'll modified the cost function used in 'calib_sofun' to calibrate the parameters using only the daily gpp and / or le value with a quality flag higher than 0.8. each modification of the original function are indicated with the comment "MODIFIED"


```{r}
# modfied RMSE cost function

# !!! comment with  MODIFIED is where I modify the function
modified_cost_rmse_pmodel <- function(
    par,  # ordered vector of model parameters
    obs, 
    drivers,
    targets,    
    par_fixed = NULL, # non-calibrated model parameters
    target_weights = NULL, # if using several targets, how are the individual 
    # RMSE weighted? named vector
    parallel = FALSE,
    ncores = 2
){
  # NOTE(fabian): These different cost functions share a LOT of code in common. Consider consolidation for maintainability?
  
  # predefine variables for CRAN check compliance
  sitename <- data <- gpp_mod <- NULL
  
  if (!("use_phydro" %in% colnames(drivers$params_siml[[1]]))){
    warning("Parameter use_phydro not set. Assuming FALSE")
    using_phydro = FALSE
  } else {
    using_phydro = drivers$params_siml[[1]]$use_phydro
  }
  
  ## define required parameter set based on model parameters
  if (!using_phydro){
    required_param_names <- rsofun:::required_param_names$p_model
  } else {
    required_param_names <- rsofun:::required_param_names$phydro_model
  }
  
  ## if WHC is treated as calibratable, remove it from par and overwrite site 
  ## info with the same value for (calibrated) WHC for all sites.
  if ("whc" %in% names(par)){
    overwrite_whc <- par[["whc"]]
    par <- par[ ! names(par) %in% c("whc") ]
    lapply(drivers$site_info, function(x) within(x, whc <- overwrite_whc))
  }
  
  ## split calibrated parameters into model and error parameters
  par_calibrated_model <- par[ ! names(par) %in% c("err_gpp") ] # consider only model parameters for the check
  
  # par_calibrated_errormodel <- par[   names(par) %in% c("err_gpp") ]
  # par_fixed
  
  ## check parameters
  if (!identical(sort(c(names(par_calibrated_model), names(par_fixed))), required_param_names)){
    stop(sprintf(paste0("Error: Input calibratable and fixed parameters do not ",
                        "match required model parameters:",
                        "\n         par:       c(%s)",
                        "\n         par_fixed: c(%s)",
                        "\n         required:  c(%s)"),
                 paste0(sort(names(par_calibrated_model)), collapse = ", "),
                 paste0(sort(names(par_fixed)), collapse = ", "),
                 paste0(sort(required_param_names), collapse = ", ")))
  }
  
  # Combine fixed and estimated params to result in all the params required to run the model
  # This basically uses all params except those of the error model of the observations
  params_modl <- c(par, par_fixed)[required_param_names]
  
  ## run the model
  df <- runread_pmodel_f(
    drivers, 
    par = params_modl,
    makecheck = TRUE,
    parallel = FALSE
  )
  
  ## clean model output and unnest
  df <- df |>
    dplyr::rowwise() |>
    dplyr::reframe(
      cbind(sitename, data[, c('date', unique(c('gpp', targets)))]) |>
        stats::setNames(c('sitename', 'date', paste0(unique(c('gpp', targets)), '_mod')))
    ) # gpp is used to get average trait prediction
  
  # separate validation data into fluxes and traits, site by site
  is_flux <- apply(obs, 1, function(x){ 'date' %in% colnames(x$data)})
  
  if(sum(is_flux) > 0){
    flux_sites <- obs$sitename[is_flux]
    
    # Unnest flux observations for our targets
    obs_flux <- obs[is_flux, ] |>
      dplyr::select(sitename, data) |>
      tidyr::unnest(data) |>
      # MODIFIED
      dplyr::select(any_of(c('sitename', 'date', targets,paste0(targets,"_qc"))))
    
    if(ncol(obs_flux) < 3){
      warning("Dated observations (fluxes) are missing for the chosen targets.")
      df_flux <- data.frame()
    }else{
      # Join P-model output and flux observations
      df_flux <- df |>
        dplyr::filter(sitename %in% flux_sites) |>
        dplyr::left_join(
          obs_flux, 
          by = c('sitename', 'date'))    # observations with missing date are ignored
    }
  }else{
    df_flux <- data.frame()
  }
  
  if(sum(!is_flux) > 0){
    trait_sites <- obs$sitename[!is_flux]
    
    # Unnest trait observations for our targets
    obs_trait <- obs[!is_flux, ] |>
      dplyr::select(sitename, data) |>
      tidyr::unnest(data) |>
      # MODIFIED
      dplyr::select(any_of(c('sitename', targets,paste0(targets,"_qc"))))
    
    if(ncol(obs_trait) < 2){
      warning("Non-dated observations (traits) are missing for the chosen targets.")
      df_trait <- data.frame()
    }else{
      # Join output and trait observations
      df_trait <- df |>
        dplyr::filter(sitename %in% trait_sites) |>
        dplyr::group_by(sitename) |>
        # get growing season average traits
        dplyr::summarise(across(ends_with("_mod") & !starts_with('gpp'),
                                ~ sum(.x * gpp_mod/sum(gpp_mod)),
                                .names = "{.col}")) |>
        dplyr::left_join(
          obs_trait,
          by = c('sitename')        # compare yearly averages rather than daily obs
        )
    }
  }else{
    df_trait <- data.frame()
  }
  
  # Calculate cost (RMSE) per target
  rmse <- lapply(targets, function(target){
    if(target %in% colnames(df_flux)){
      
      # MODIFIED
      df_flux <- df_flux |> filter(if_all(ends_with("_qc"), ~ . > 0.8))

      
      error <- (df_flux[[target]] - df_flux[[paste0(target, '_mod')]])^2
    }else{
      error <- c()
    }
    if(target %in% colnames(df_trait)){
      
      # MODIFIED
      df_trait <- df_trait |> filter(if_all(ends_with("_qc"), ~ . > 0.8))

      error <- c(error, 
                 (df_trait[[target]] - df_trait[[paste0(target, '_mod')]])^2)
    }
    sqrt(mean(error, na.rm = TRUE))
  }) |>
    unlist()
  
  # Aggregate RMSE over targets (weighted average)
  if(!is.null(target_weights)){
    cost <- sum(rmse * target_weights)
  }else{
    cost <- mean(rmse, na.rm = TRUE)
  }
  
  return(cost)
}

```


I'll use the site FR-Pue. I'll run the simulation using the Penmann-Montheith equation using non-calibrated and calibrated parameter

```{r}
# I select the site US-SRG beacuse show the highest gpp qc

single_site <- driver[driver$sitename == "FR-Pue",]

single_site <- single_site |> unnest(params_siml) |>
  mutate(use_gs = TRUE,
         use_phydro = FALSE,
         use_pml= TRUE) |>
  group_by(sitename) |>
  nest(params_siml = c(spinup, spinupyears, recycle, outdt, ltre,  ltne,  ltrd,  ltnd,  lgr3,  lgn3,  lgr4 ,
                       use_gs, use_phydro, use_pml))

```

## Run with non-calibrated parameter

```{r, fig.width=8, fig.height=4}
# P model run and plot WITHOUT calibration
params_modl <- list(
  kphio              = 0.04998,    # setup ORG in Stocker et al. 2020 GMD
  kphio_par_a        = 0.0,        # set to zero to disable temperature-dependence of kphio
  kphio_par_b        = 1.0,
  soilm_thetastar    = 0.6 * 240,  # to recover old setup with soil moisture stress
  beta_unitcostratio = 146.0,
  rd_to_vcmax        = 0.014,      # value from Atkin et al. 2015 for C3 herbaceous
  tau_acclim         = 30.0,
  kc_jmax            = 0.41
)

output <- runread_pmodel_f(
  single_site,
  par = params_modl
)

df_plot <- output |>
  unnest(data) |>
  select(date, mod = gpp) |> 
  left_join(
    single_site |>
      unnest(forcing) |> 
      select(date, obs = gpp),
    by = join_by(date)
  )

plot_eval(df_plot)
```


## Calibration using GenSa

I keep 1000 iterations to allow a fast check

```{r}
# calibration

settings <- list(
  method              = "GenSA",
  metric              = modified_cost_rmse_pmodel,
  control = list(
    maxit = 1000),
  par = list(
    kphio = list(lower=0.03, upper=0.2, init = 0.05),
    kphio_par_a = list(lower = -0.0004, upper = 0.001, init = -0.0025),
    kphio_par_b = list(lower = 10, upper = 30, init = 20),
    soilm_thetastar = list(lower  = 0, upper = 240, init = 144)
  )
)

evaluation <- single_site |>
  unnest(forcing) |>
  select(sitename,date,gpp,gpp_qc) |>
  group_by(sitename) |>
  nest(data = c(date,gpp,gpp_qc))


pars <- calib_sofun(
  drivers = single_site,
  obs = evaluation,
  settings = settings,
  targets = "gpp",
  par_fixed = list(
    beta_unitcostratio = 146.0,
    rd_to_vcmax        = 0.014,
    tau_acclim         = 30.0,
    kc_jmax            = 0.41
  )
)

```

```{r, fig.width=8, fig.height=4}
# P model run and plot WITH calibration
params_modl <- list(
  kphio              = pars$par[["kphio"]],
  kphio_par_a        = pars$par[["kphio_par_a"]],
  kphio_par_b        = pars$par[["kphio_par_b"]],
  rd_to_vcmax        = 0.014,
  soilm_thetastar    = pars$par[["soilm_thetastar"]],
  beta_unitcostratio = 146,
  tau_acclim         = 30,
  kc_jmax            = 0.54131889
)

df_plot <- output |>
  unnest(data) |>
  select(date, mod = gpp) |> 
  left_join(
    single_site |>
      unnest(forcing) |> 
      select(date, obs = gpp),
    by = join_by(date)
  )

plot_eval(df_plot)

```

There is an improvement in GPP simulation after the calibration
